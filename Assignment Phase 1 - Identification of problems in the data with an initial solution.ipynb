{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce17776",
   "metadata": {},
   "source": [
    "# 2) Identification of problems in the data with an initial solution (5b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd25ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import pylab as py\n",
    "\n",
    "from numpy import isnan\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79de87ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = pd.read_csv(\"Data Source/007/measurements.csv\", sep='\\t', lineterminator='\\n', na_values='?')\n",
    "stations = pd.read_csv(\"Data Source/007/stations.csv\", sep='\\t', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d893667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure that the data was properly loaded. \n",
    "measurements.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf76438b",
   "metadata": {},
   "source": [
    "## 2.1) Data Cleaning & Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c676930",
   "metadata": {},
   "source": [
    "In this section we will have a closer look at the quality of the data for each dataset seperatly.\n",
    "- We will check for dublicated reccords, inconsistent formats, missing values, skewed values and more.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddebc5f4",
   "metadata": {},
   "source": [
    "Based on this, we can see that there are 179 dublicated reccords in the measurements data frame. we could potentially just remove all dublicates, but it would be too early to do so at this point, since we dont know the full context of the data frame. we are missing the timestamp for the reccords. we will first have a look at the other file, and then determine a course of action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea0970",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3975cca",
   "metadata": {},
   "source": [
    "unlike the measurements, we do not experience any dublicated reccords in the stations dataset. so at this point, one would assume that the two files should be interconnected.\n",
    "\n",
    "We therefore start by looking at the amount of reccords, to see if they are equal to eachother."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c54ba4",
   "metadata": {},
   "source": [
    "### 2.1.1) Initial data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cac039",
   "metadata": {},
   "source": [
    "In this section, we will start off by converting the dataset to a format which we believe would be more suitable for the comming tasks, where the changes include:\n",
    "* correction of inappropriate data structure\n",
    "* follow up on duplicate records\n",
    "* inconsistent formats\n",
    "* missing values\n",
    "* skewed values.\n",
    "* and more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f1531b",
   "metadata": {},
   "source": [
    "#### 2.1.1.1) Stations dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de29879",
   "metadata": {},
   "source": [
    "When looking at the formatting of the 'revision' column, we can see that there are at lease two types of formatting, dd/mm/yyyy, hh:mm:ss and then also only dd/mm/yyyy. We replace the existing formating with a datetime format. Also, we add two new columns which only comprize of the year and month, this is done for the sake of simplefying some functions when plotting and etc. \n",
    "\n",
    "as for the location column, since we dont nessecarily wish to see both the contenent and city on the plots, we split the values into two new columns, namely ['Contenent'] and ['City'], and remove the original column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e376810",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d4d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations['revision'] = pd.to_datetime(stations[\"revision\"]).dt.date\n",
    "stations = stations.set_index(pd.DatetimeIndex(stations['revision']))\n",
    "\n",
    "stations['year'] = pd.to_datetime(stations['revision']).dt.year\n",
    "stations['month'] = pd.to_datetime(stations['revision']).dt.month\n",
    "stations[['Region', 'City']] = stations['location'].str.split('/', 1, expand=True)\n",
    "stations = stations.drop(columns=['location'])\n",
    "\n",
    "# df['QoS'].unique()\n",
    "stations['QoS'] = stations['QoS'].replace(['accep','maitennce'], ['acceptable','maintenance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41459a4b",
   "metadata": {},
   "source": [
    "#### 2.1.1.2) measurements dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2595c34b",
   "metadata": {},
   "source": [
    "as it turnes out, the datatype for the warning was initially a floating point, which was used to represent a boolean state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ddde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a2039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements['warning'] = measurements['warning'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df811f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f0ebbd",
   "metadata": {},
   "source": [
    "#### 2.1.1.3) KNN Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7435fd6",
   "metadata": {},
   "source": [
    "checking for missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593a40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ab740d",
   "metadata": {},
   "source": [
    "As we can see, there are 15 columns which have missing values, we can see this by counting the isna() boolean results, and as these are greater than 0 there are values missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4619e510",
   "metadata": {},
   "source": [
    "The KNNImputer is a data transform that is first configured based on the method used to estimate the missing values The default distance measure is a Euclidean distance measure that is NaN aware\n",
    "The number of neighbors is set to 5 by default and can be configured by the n_neighbors argument. \n",
    "\n",
    "in order to read the missing values as NaN, we need to add *na_values='?'* to the *read_csv()* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62edbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knnimputer = KNNImputer(n_neighbors=5)\n",
    "measurements.iloc[:,:] = knnimputer.fit_transform(measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17179be",
   "metadata": {},
   "source": [
    "to validate, we can print use the same functions as before like printing out the datqaset to see if it has the same structure and get the sum of the NaN values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b74eaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b71b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eacd9c",
   "metadata": {},
   "source": [
    "Everything looks fine !!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b53501d",
   "metadata": {},
   "source": [
    "#### 2.1.1.4) Data Normalization and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272db1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e78eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"reccord count of stations: {0}\".format(len(stations.index)))\n",
    "print(\"reccord count of measurements: {0}\".format(len(measurements.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b26aaca",
   "metadata": {},
   "source": [
    "as it turnes out, the two files are no where near the same length. so we need to have a closer look at alternative commonalities of the two files. and as it turnes out, both files consist of the longditude and latitude coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784693ca",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b4e048",
   "metadata": {},
   "source": [
    "In the following we are joining the data series from both files, and the only common denumerator between the two files are the longditude and latitude coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc46ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(stations, measurements, how='inner', left_on = 'longitude', right_on = 'longitude')\n",
    "df = df.set_index(pd.DatetimeIndex(df['revision']))\n",
    "df = df.drop_duplicates()\n",
    "df['latitude'] = df['latitude_y']\n",
    "df = df.drop(columns=['latitude_x', 'latitude_y', 'revision'])\n",
    "\n",
    "\n",
    "df['warning'] = df['warning'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea5e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6797c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'Dataset.csv'\n",
    "df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c38e07c",
   "metadata": {},
   "source": [
    "# ------------------------------------------END------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a996d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_df = df['2014-01-01':'2015-01-01']\n",
    "sns.displot(rslt_df, x=\"NOx\", bins=20, hue='warning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755c40d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pylab as py\n",
    "\n",
    "sm.qqplot(df['NOx'], line='45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b47d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rslt_df = df.drop(['latitude', 'longitude', 'month', 'year', 'H2CO', 'PRES', 'C2H3NO5', 'CO', 'PM2.5', 'CH4', 'SO2', 'O3', 'PAHs', 'PM10', 'NH3', 'NOx', 'CFCs', 'Pb'], axis=1)\n",
    "\n",
    "sns.set_theme(style=\"ticks\")\n",
    "sns.pairplot(rslt_df, hue=\"warning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ef9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df['2014-01-01':'2016-01-12'].drop(['year', 'latitude', 'longitude','month', 'PRES'], axis=1)\n",
    "df_tmp.plot(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27991c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df.drop(['year', 'latitude', 'longitude','month', 'PRES', 'warning', 'H2CO', 'C2H3NO5', 'CO', 'PM2.5', 'CH4', 'SO2', 'O3', 'PAHs', 'PM10', 'NH3', 'NOx'], axis=1)\n",
    "df_tmp.plot(kind='hist', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TEMP'].plot(kind='hist', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b6159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = \"year\", y = \"TEMP\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e0beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x = \"year\", y = \"TEMP\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929426f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2989ec64",
   "metadata": {},
   "source": [
    "**At this point, we need to make a judgement call based on the following.**\n",
    "\n",
    "    1) what we can see is that we have thousands of measurements, and allthough they might be completely valid, they are out of context as long as we dont have the timestamp on them.\n",
    "    \n",
    "    2) we can see that the count of reccords are not impacted by a inner or outer join, so thats fine, but we do experience a discrepancy between the longditude and latitude. \n",
    "    - Joining on the longditude column results in 24785 reccords with 353 dublicates and \n",
    "    - Joining on the latitude column results in 24737 reccords with 352 dublicated values\n",
    "    \n",
    "since joining on the longditude column yeals in a bigger result, we will continue the analasys based on these, and we will also remove the dublicated reccords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9516f73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['QoS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3529d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(data=df, x=['2016':'2017'], y=\"TEMP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd721d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x = \"year\", y = \"TEMP\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x = \"year\", y = \"CFCs\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061d3fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=df, x=\"year\", y=\"CFCs\",\n",
    "    col=\"QoS\", hue=\"warning\", style=\"warning\",\n",
    "    kind=\"line\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48808dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=df, x=\"year\", y=\"TEMP\",\n",
    "    col=\"warning\", hue=\"QoS\", style=\"QoS\",\n",
    "    kind=\"line\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f9c16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7864987",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc['2014-01-01':'2015-01-01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd7dc2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557db383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2dc1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a015d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"dark\")\n",
    "\n",
    "# Plot each year's time series in its own facet\n",
    "g = sns.relplot(\n",
    "    data=df,\n",
    "    x=\"month\", y=\"TEMP\", col=\"year\", hue=\"year\",\n",
    "    kind=\"line\", palette=\"crest\", linewidth=4, zorder=5,\n",
    "    col_wrap=3, height=2, aspect=1.5, legend=False,\n",
    ")\n",
    "\n",
    "# Iterate over each subplot to customize further\n",
    "for year, ax in g.axes_dict.items():\n",
    "\n",
    "    # Add the title as an annotation within the plot\n",
    "    ax.text(.8, .85, year, transform=ax.transAxes, fontweight=\"bold\")\n",
    "\n",
    "    # Plot every year's time series in the background\n",
    "    sns.lineplot(\n",
    "        data=df, x=\"month\", y=\"TEMP\", units=\"year\",\n",
    "        estimator=None, color=\".7\", linewidth=1, ax=ax,\n",
    "    )\n",
    "\n",
    "# Reduce the frequency of the x axis ticks\n",
    "ax.set_xticks(ax.get_xticks()[::2])\n",
    "\n",
    "# Tweak the supporting aspects of the plot\n",
    "g.set_titles(\"\")\n",
    "g.set_axis_labels(\"\", \"TEMP\")\n",
    "g.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a4aa91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff85fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "vscode": {
   "interpreter": {
    "hash": "bb6d78a5596d6032bc2fc4ef79bfa133fda0cd9e4af8ffb50defa778536fdc5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
